#case it will be three independent priors for the variances).
mod_string = " model {
for (i in 1:length(y)) {
y[i] ~ dnorm(mu[grp[i]], prec[grp[i]])
}
for (j in 1:3) {
mu[j] ~ dnorm(0.0, 1.0/1.0e6)
}
for (k in 1:3) {
prec[k] ~ dgamma(5/2.0, 5*1.0/2.0)
}
sig = sqrt( 1.0 / prec )
} "
set.seed(82)
str(PlantGrowth)
data_jags = list(y=PlantGrowth$weight,
grp=as.numeric(PlantGrowth$group))
params = c("mu", "sig")
inits = function() {
inits = list("mu"=rnorm(3,0.0,100.0), "prec"=rgamma(3,1.0,1.0))
}
mod2 = jags.model(textConnection(mod_string), data=data_jags, inits=inits, n.chains=3)
update(mod, 1e3)
data("PlantGrowth")
library("rjags")
data("PlantGrowth")
library("rjags")
library("coda")
#-------JAGS
#-------Mudan√ßas:####
#Re-fit the JAGS model on plant growth from the lesson with
#a separate variance for each of the three groups.
#To do so, modify the model code to index the precision in
#the normal likelihood by group, just as we did with the mean.
#Use the same priors as the original model (except in this
#case it will be three independent priors for the variances).
ame priors as the original model (except in this
#case it will be three independent priors for the variances).
mod_string = " model {
for (i in 1:length(y)) {
y[i] ~ dnorm(mu[grp[i]], prec[grp[i]])
}
for (j in 1:3) {
mu[j] ~ dnorm(0.0, 1.0/1.0e6)
}
for (k in 1:3) {
prec[k] ~ dgamma(5/2.0, 5*1.0/2.0)
}
sig = sqrt( 1.0 / prec )
} "
set.seed(82)
str(PlantGrowth)
data_jags = list(y=PlantGrowth$weight,
grp=as.numeric(PlantGrowth$group))
params = c("mu", "sig")
inits = function() {
inits = list("mu"=rnorm(3,0.0,100.0), "prec"=rgamma(3,1.0,1.0))
}
mod2 = jags.model(textConnection(mod_string), data=data_jags, inits=inits, n.chains=3)
update(mod, 1e3)
mod_string = " model {
for (i in 1:length(y)) {
y[i] ~ dnorm(mu[grp[i]], prec[grp[i]])
}
for (j in 1:3) {
mu[j] ~ dnorm(0.0, 1.0/1.0e6)
}
for (k in 1:3) {
prec[k] ~ dgamma(5/2.0, 5*1.0/2.0)
}
sig = sqrt( 1.0 / prec )
} "
set.seed(82)
str(PlantGrowth)
data_jags = list(y=PlantGrowth$weight,
grp=as.numeric(PlantGrowth$group))
params = c("mu", "sig")
inits = function() {
inits = list("mu"=rnorm(3,0.0,100.0), "prec"=rgamma(3,1.0,1.0))
}
mod2 = jags.model(textConnection(mod_string), data=data_jags, inits=inits, n.chains=3)
update(mod, 1e3)
mod_string = " model {
for (i in 1:length(y)) {
y[i] ~ dnorm(mu[grp[i]], prec[grp[i]])
}
for (j in 1:3) {
mu[j] ~ dnorm(0.0, 1.0/1.0e6)
}
for (k in 1:3) {
prec[k] ~ dgamma(5/2.0, 5*1.0/2.0)
}
sig = sqrt( 1.0 / prec )
} "
set.seed(82)
str(PlantGrowth)
data_jags = list(y=PlantGrowth$weight,
grp=as.numeric(PlantGrowth$group))
params = c("mu", "sig")
inits = function() {
inits = list("mu"=rnorm(3,0.0,100.0), "prec"=rgamma(3,1.0,1.0))
}
mod2 = jags.model(textConnection(mod_string), data=data_jags, inits=inits, n.chains=3)
update(mod2, 1e3)
PlantGrowth$weight
PlantGrowth$group
dat$Correct
dat$Trials
data_jags
length(data_jags)
X = model.matrix(mod_glm)[,-1] # -1 removes the column of 1s for the intercept
head(X)
#Use
#three chains
#with at least 5,000 iterations in each.
mod_string = " model {
for (i in 1:length(y)) {
y[i] ~ dbin(phi[i], n[i])
logit(phi[i]) = b0 + b[1]*Age[i] + b[2]*OMElow[i] + b[3]*Loud[i] + b[4]*Noiseincoherent[i]
}
b0 ~ dnorm(0.0, 1.0/5.0^2)
for (j in 1:4) {
b[j] ~ dnorm(0.0, 1.0/4.0^2)
}
} "
data_jags = as.list(as.data.frame(X))
data_jags$y = dat$Correct # this will not work if there are missing values in dat (because they would be ignored by model.matrix). Always make sure that the data are accurately pre-processed for JAGS.
data_jags$n = dat$Trials
str(data_jags) # make sure that all variables have the same number of observations (712).
params = c("phi", "n")
inits = function() {
inits = list("phi"=rnorm(3,0.0,100.0),
"n"=rgamma(3,1.0,1.0))
}
mod = jags.model(textConnection(mod_string),
data=data_jags,
inits=inits,
n.chains=3)
update(mod, 1e2) #depois mude para 5e3
t a similar model in JAGS.####
X = model.matrix(mod_glm)[,-1] # -1 removes the column of 1s for the intercept
head(X)
#Use
#three chains
#with at least 5,000 iterations in each.
mod_string = " model {
for (i in 1:length(y)) {
y[i] ~ dbin(phi[i], n[i])
logit(phi[i]) = b0 + b[1]*Age[i] + b[2]*OMElow[i] + b[3]*Loud[i] + b[4]*Noiseincoherent[i]
}
b0 ~ dnorm(0.0, 1.0/5.0^2)
for (j in 1:4) {
b[j] ~ dnorm(0.0, 1.0/4.0^2)
}
} "
data_jags = as.list(as.data.frame(X))
data_jags$y = dat$Correct # this will not work if there are missing values in dat (because they would be ignored by model.matrix). Always make sure that the data are accurately pre-processed for JAGS.
data_jags$n = dat$Trials
str(data_jags) # make sure that all variables have the same number of observations (712).
params = c("phi")#, "n")
inits = function() {
inits = list("phi"=rnorm(3,0.0,100.0),
"n"=rgamma(3,1.0,1.0))
}
mod = jags.model(textConnection(mod_string),
data=data_jags,
inits=inits,
n.chains=3)
update(mod, 1e2) #depois mude para 5e3
length(dat$Correct)
head(X)
X
e chains
#with at least 5,000 iterations in each.
mod_string = " model {
for (i in 1:length(y)) {
y[i] ~ dbin(phi[i], n[i])
logit(phi[i]) = b0 + b[1]*Age[i] + b[2]*OMElow[i] + b[3]*Loud[i] + b[4]*Noiseincoherent[i]
}
b0 ~ dnorm(0.0, 1.0/5.0^2)
for (j in 1:4) {
b[j] ~ dnorm(0.0, 1.0/4.0^2)
}
} "
data_jags = as.list(as.data.frame(X))
length(dat$Correct)
data_jags$y = dat$Correct # this will not work if there are missing values in dat (because they would be ignored by model.matrix). Always make sure that the data are accurately pre-processed for JAGS.
data_jags$n = dat$Trials
str(data_jags) # make sure that all variables have the same number of observations (712).
params = c("phi", "n")
inits = function() {
inits = list("phi"=rnorm(3,0.0,100.0),
"n"=rgamma(3,1.0,1.0))
}
mod = jags.model(textConnection(mod_string),
data=data_jags,
inits=inits,
n.chains=3)
update(mod, 1e2) #depois mude para 5e3
mod_sim = coda.samples(model=mod,
variable.names=params,
n.iter=1e3)
fit a similar model in JAGS.####
X = model.matrix(mod_glm)[,-1] # -1 removes the column of 1s for the intercept
head(X)
#Use
#three chains
#with at least 5,000 iterations in each.
mod_string = " model {
for (i in 1:length(y)) {
y[i] ~ dbin(phi[i], n[i])
logit(phi[i]) = b0 + b[1]*Age[i] + b[2]*OMElow[i] + b[3]*Loud[i] + b[4]*Noiseincoherent[i]
}
b0 ~ dnorm(0.0, 1.0/5.0^2)
for (j in 1:4) {
b[j] ~ dnorm(0.0, 1.0/4.0^2)
}
} "
data_jags = as.list(as.data.frame(X))
length(dat$Correct)
data_jags$y = dat$Correct # this will not work if there are missing values in dat (because they would be ignored by model.matrix). Always make sure that the data are accurately pre-processed for JAGS.
data_jags$n = dat$Trials
str(data_jags) # make sure that all variables have the same number of observations (712).
params = c("phi", "n")
inits = function() {
inits = list("phi"=rnorm(3,0.0,100.0),
"n"=rgamma(3,0.0,100.0))
}
mod = jags.model(textConnection(mod_string),
data=data_jags,
inits=inits,
n.chains=3)
update(mod, 1e2) #depois mude para 5e3
inits = list("mu"=rnorm(3,0.0,100.0), "prec"=rgamma(3,1.0,1.0))
inits
l fit a reference logistic regression model with ####
#noninformative prior in R.
mod_glm = glm(Correct/Trials ~ Age + OME + Loud + Noise,
data=dat, weights=Trials, family="binomial")
summary(mod_glm)
plot(residuals(mod_glm, type="deviance"))
plot(fitted(mod_glm), dat$Correct/dat$Trials)
#Next, we will fit a similar model in JAGS.####
X = model.matrix(mod_glm)[,-1] # -1 removes the column of 1s for the intercept
head(X)
#Use
#three chains
#with at least 5,000 iterations in each.
mod_string = " model {
for (i in 1:length(y)) {
y[i] ~ dbin(phi[i], n[i])
logit(phi[i]) = b0 + b[1]*Age[i] + b[2]*OMElow[i] + b[3]*Loud[i] + b[4]*Noiseincoherent[i]
}
b0 ~ dnorm(0.0, 1.0/5.0^2)
for (j in 1:4) {
b[j] ~ dnorm(0.0, 1.0/4.0^2)
}
} "
data_jags = as.list(as.data.frame(X))
length(dat$Correct)
data_jags$y = dat$Correct # this will not work if there are missing values in dat (because they would be ignored by model.matrix). Always make sure that the data are accurately pre-processed for JAGS.
data_jags$n = dat$Trials
str(data_jags) # make sure that all variables have the same number of observations (712).
params = c("phi", "n")
inits = function() {
inits = list("phi"=rnorm(3,0.0,100.0),
"n"=rgamma(3,1.0,1.0))
}
mod = jags.model(textConnection(mod_string),
data=data_jags,
inits=inits,
n.chains=3)
update(mod, 1e2) #depois mude para 5e3
mod_sim = coda.samples(model=mod,
variable.names=params,
n.iter=1e3)
library("rjags")
library("coda")
library("MASS")
data("OME")
?OME # background on the data
head(OME)
any(is.na(OME)) # check for missing values
dat = subset(OME, OME != "N/A") # manually remove OME missing values identified with "N/A"
dat$OME = factor(dat$OME)
str(dat)
plot(dat$Age, dat$Correct / dat$Trials )
plot(dat$OME, dat$Correct / dat$Trials )
plot(dat$Loud, dat$Correct / dat$Trials )
plot(dat$Noise, dat$Correct / dat$Trials )
#Next, we'll fit a reference logistic regression model with ####
#noninformative prior in R.
mod_glm = glm(Correct/Trials ~ Age + OME + Loud + Noise,
data=dat, weights=Trials, family="binomial")
summary(mod_glm)
plot(residuals(mod_glm, type="deviance"))
plot(fitted(mod_glm), dat$Correct/dat$Trials)
#Next, we will fit a similar model in JAGS.####
X = model.matrix(mod_glm)[,-1] # -1 removes the column of 1s for the intercept
head(X)
#at least 5,000 iterations in each.
mod_string = " model {
for (i in 1:length(y)) {
y[i] ~ dbin(phi[i], n[i])
logit(phi[i]) = b0 + b[1]*Age[i] + b[2]*OMElow[i] + b[3]*Loud[i] + b[4]*Noiseincoherent[i]
}
b0 ~ dnorm(0.0, 1.0/5.0^2)
for (j in 1:4) {
b[j] ~ dnorm(0.0, 1.0/4.0^2)
}
} "
data_jags = as.list(as.data.frame(X))
data_jags$y = dat$Correct # this will not work if there are missing values in dat (because they would be ignored by model.matrix). Always make sure that the data are accurately pre-processed for JAGS.
data_jags$n = dat$Trials
str(data_jags) # make sure that all variables have the same number of observations (712).
params = c("b0", "b") #mudei p/ b0
mod1 = jags.model(textConnection(mod1_string),
data=data_jags,
n.chains=3)
update(mod1, 1e3)
mod1_sim = coda.samples(model=mod1,
variable.names=params,
n.iter=5e3)
mod1_csim = as.mcmc(do.call(rbind, mod1_sim))
iterations in each.
mod1_string = " model {
for (i in 1:length(y)) {
y[i] ~ dbin(phi[i], n[i])
logit(phi[i]) = b0 + b[1]*Age[i] + b[2]*OMElow[i] + b[3]*Loud[i] + b[4]*Noiseincoherent[i]
}
b0 ~ dnorm(0.0, 1.0/5.0^2)
for (j in 1:4) {
b[j] ~ dnorm(0.0, 1.0/4.0^2)
}
} "
data_jags = as.list(as.data.frame(X))
data_jags$y = dat$Correct # this will not work if there are missing values in dat (because they would be ignored by model.matrix). Always make sure that the data are accurately pre-processed for JAGS.
data_jags$n = dat$Trials
str(data_jags) # make sure that all variables have the same number of observations (712).
params = c("b0", "b") #mudei p/ b0
mod1 = jags.model(textConnection(mod1_string),
data=data_jags,
n.chains=3)
update(mod1, 1e3)
mod1_sim = coda.samples(model=mod1,
variable.names=params,
n.iter=5e3)
mod1_csim = as.mcmc(do.call(rbind, mod1_sim))
## convergence diagnostics
plot(mod1_sim, ask=TRUE)
gelman.diag(mod1_sim)
autocorr.plot(mod1_sim)
raftery.diag(mod1_sim) #incluido
summary(mod1_sim)
pm_coef = colMeans(mod1_csim)
pm_coef
summary(mod1_csim)
pm_coef[,1]
pm_coef[1,]
pm_coef[1,]
pm_coef[1,1]
pm_coef = colMeans(mod1_csim)
pm_coef
pm_coef[1,1]
objects(pm_coef)
typeof(pm_coef)
pm_coef$b[1]
mod1_csim[1,1]
summary(mod1_csim)
mod1_csim[1,1]
b2 <- mod1_csim[2,1]
mod1_csim[2,1]
mod1_csim[1,1]
mod1_csim[,1]
summary(mod1_csim)
mod1_csim[1,1]
summary(mod1_csim)[1,1]
s[1,1]
s <- summary(mod1_csim)
s[1,1]
summary(mod1_csim)[1,1]
summary(mod1_csim)[1,2]
summary(mod1_csim)[2,2]
mean(mod1_csim)
typeof(summary(mod1_csim))
colnames(summary(mod1_csim))
summary(mod1_csim)[0,1]
summary(mod1_csim)[1,1]
pm_coef
colMeans(mod1_csim)
colMeans(1,mod1_csim)
colMeans(1,1,mod1_csim)
colMeans(1,1, mod1_csim)
colMeans([1,1], mod1_csim)
colMeans(mod1_csim)
colMeans(mod1_csim,1)
?colMeans
.colMeans(1,1,mod1_csim)
.colMeans(1,1,mod1_csim)
.colMeans(1,2,mod1_csim)
.colMeans(2,1,mod1_csim)
pm_coef = colMeans(mod1_csim)
pm_coef
summary(mod1_csim)
pm_coef = colMeans(mod1_csim)
pm_coef[1:3]
pm_coef
pm_coef[1:1]
pm_coef[2:2]
pm_coef[1]
pm_coef[2]
pm_coef = colMeans(mod1_csim)
prob <- 1/(1+e^(-(pm_coef[1]*60+pm_coef[2]*1+pm_coef[3]*50+pm_coef[4]*0)))
prob <- 1/(1+exp(-(pm_coef[1]*60+pm_coef[2]*1+pm_coef[3]*50+pm_coef[4]*0)))
prob
prob <- 1/(1+exp(-(pm_coef[1]*60 + pm_coef[2]*1 + pm_coef[3]*50 + pm_coef[4]*0)))
prob
prob <- 1/(1+exp(-(pm_coef[1]*60 + pm_coef[2]*0 + pm_coef[3]*50 + pm_coef[4]*0)))
prob
prob <- 1/(1+exp(-(pm_coef[1]*60*0 + pm_coef[2]*0 + pm_coef[3]*50*0 + pm_coef[4]*0)))
prob
prob <- 1/(1+exp(-(pm_coef[1]*60 + pm_coef[2]*0 + pm_coef[3]*50 + pm_coef[4]*0)))
prob
pm_coef
pm_coef[5]
prob <- 1/(1+exp(-(pm_coef[5]+pm_coef[1]*60 + pm_coef[2]*0 + pm_coef[3]*50 + pm_coef[4]*0)))
prob
probabilidade <- ppois(22, 30)
probabilidade
?ppois
probabilidade <- ppois(1, 30)
probabilidade
probabilidade <- ppois(50, 30)
probabilidade
probabilidade <- ppois(666, 30)
probabilidade
probabilidade <- ppois(22, 30)
probabilidade
#2----------
#install.packages("COUNT")
library("COUNT")
data("badhealth")
head(badhealth)
any(is.na(badhealth))
hist(badhealth$numvisit, breaks=20)
#7####
library("rjags")
mod_string = " model {
for (i in 1:length(calls)) {
calls[i] ~ dpois( lam[i] )
lam[i] = int + b[1]*age[i] + b[2]*isgroup2[i]
}
int ~ dnorm(0.0, 1.0/1e2)
b[1] ~ dnorm(0.0, 1.0/1e2)
b[2] ~ dnorm(0.0, 1.0/1e2)
} "
data_jags = as.list(dat)
#params = c("int", "b_badh", "b_age", "b_intx")
params = c("b0", "b[1]", "b[2]")
mod = jags.model(textConnection(mod_string), data=data_jags, n.chains=3)
update(mod, 1e3)
mod_sim = coda.samples(model=mod,
variable.names=params,
n.iter=5e3)
mod_csim = as.mcmc(do.call(rbind, mod_sim))
## convergence diagnostics
plot(mod_sim)
gelman.diag(mod_sim)
autocorr.diag(mod_sim)
autocorr.plot(mod_sim)
effectiveSize(mod_sim)
## compute DIC
dic = dic.samples(mod, n.iter=1e3)
dic
mod_string = " model {
for (i in 1:length(calls)) {
calls[i] ~ dpois( lam[i] )
lam[i] = int + b[1]*age[i] + b[2]*isgroup2[i]
}
int ~ dnorm(0.0, 1.0/1e2)
b[1] ~ dnorm(0.0, 1.0/1e2)
b[2] ~ dnorm(0.0, 1.0/1e2)
} "
data_jags = as.list(dat)
boxplot(dat)
#5####
#resp: calls vs. \tt isgroup2 isgroup2
setwd("F:/Dropbox/code/R/Curso")
dat <- read.csv(file="caller.csv",head=TRUE,sep=",")
pairs(dat)
boxplot(dat)
boxplot(dat$calls, xlab="calls")
hist(dat$calls, 30, xlab="calls")
boxplot(dat$isgroup2)
plot(dat$calls/dat$days_active, dat$isgroup2)
plot(dat$calls, dat$isgroup2)
#resp
#calls vs. \tt isgroup2 isgroup2
library("rjags")
mod_string = " model {
for (i in 1:length(calls)) {
calls[i] ~ dpois( lam[i] )
lam[i] = int + b[1]*age[i] + b[2]*isgroup2[i]
}
int ~ dnorm(0.0, 1.0/1e2)
b[1] ~ dnorm(0.0, 1.0/1e2)
b[2] ~ dnorm(0.0, 1.0/1e2)
} "
data_jags = as.list(dat)
#params = c("int", "b_badh", "b_age", "b_intx")
params = c("b0", "b[1]", "b[2]")
mod = jags.model(textConnection(mod_string), data=data_jags, n.chains=3)
